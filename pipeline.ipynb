{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#two pipeline ingredients: the ngram counter and the classifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(ngram_range=(1,4), analyzer='word')\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\").fillna(\"\")\n",
    "test  = pd.read_csv(\"test.csv\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10158, 6), (22513, 4))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_description</th>\n",
       "      <th>median_relevance</th>\n",
       "      <th>relevance_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bridal shower decorations</td>\n",
       "      <td>Accent Pillow with Heart Design - Red/Black</td>\n",
       "      <td>Red satin accent pillow embroidered with a hea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>led christmas lights</td>\n",
       "      <td>Set of 10 Battery Operated Multi LED Train Chr...</td>\n",
       "      <td>Set of 10 Battery Operated Train Christmas Lig...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                      query  \\\n",
       "0   1  bridal shower decorations   \n",
       "1   2       led christmas lights   \n",
       "\n",
       "                                       product_title  \\\n",
       "0        Accent Pillow with Heart Design - Red/Black   \n",
       "1  Set of 10 Battery Operated Multi LED Train Chr...   \n",
       "\n",
       "                                 product_description  median_relevance  \\\n",
       "0  Red satin accent pillow embroidered with a hea...                 1   \n",
       "1  Set of 10 Battery Operated Train Christmas Lig...                 4   \n",
       "\n",
       "   relevance_variance  \n",
       "0                 0.0  \n",
       "1                 0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Jaccard similarity coefficient score\n",
    "#The Jaccard index [1], or Jaccard similarity coefficient, defined as the size of the intersection divided by the size of the union of two sets.\n",
    "\n",
    "#define regex1 for use in Jaccard function\n",
    "regex1 = re.compile('[^a-zA-Z]')\n",
    "\n",
    "def Jaccard(row):\n",
    "    words0 = regex1.sub(' ', row[0])\n",
    "    words1 = regex1.sub(' ', row[1])\n",
    "\n",
    "    words0 = set(words0.lower().split(' '))\n",
    "    words1 = set(words1.lower().split(' '))\n",
    "\n",
    "    normalizer = max(float(len(words0 | words1)), 1.0)\n",
    "    return len(words0 & words1) / normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['Jaccard'] = train[['query', 'product_title']].apply(Jaccard, axis=1)\n",
    "test['Jaccard'] = test[['query', 'product_title']].apply(Jaccard, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "# Steps: extracting the ngrams and put them through the classifier. Pipeline looks like:\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', vect),  # extract ngrams from query\n",
    "    ('clf' , clf),   # feed the output through a classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def run_experiment(X, y, pipeline, num_expts=100):\n",
    "    scores = list()\n",
    "    for i in range(num_expts):\n",
    "        X_train, X_test, y_train, y_true = train_test_split(X, y)\n",
    "        model = pipeline.fit(X_train, y_train)  # train the classifier\n",
    "        y_test = model.predict(X_test)          # apply the model to the test data\n",
    "        score = accuracy_score(y_test, y_true)  # compare the results to the gold standard\n",
    "        scores.append(score)\n",
    "\n",
    "    print (sum(scores) / num_expts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The general shape of a custom data transformer is as follows:\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "class DataTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, vars):\n",
    "        self.vars = vars # this contains whatever variables you need \n",
    "                         # to pass in for use in the `transform` step\n",
    "            \n",
    "    def transform(self, data):\n",
    "        # this is the crucial method. It takes in whatever data is passed into\n",
    "        # the tranformer as a whole, such as a Pandas dataframe or a numpy array,\n",
    "        # and returns the transformed data\n",
    "        return mydatatransform(data, self.vars)\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        # most of the time, `fit` doesn't need to do anything\n",
    "        # just return `self`\n",
    "        # exceptions: if you're writing a custom classifier,\n",
    "        #          or if how the test data is transformed is dependent on\n",
    "        #                how the training data was transformed\n",
    "        # Examples of the second type are scalers and the n-gram transformer\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the extractor\n",
    "\n",
    "class TextExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Adapted from code by @zacstewart \n",
    "       https://github.com/zacstewart/kaggle_seeclickfix/blob/master/estimator.py\n",
    "       Also see Zac Stewart's excellent blogpost on pipelines:\n",
    "       http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html\n",
    "       \"\"\"\n",
    "    \n",
    "    def __init__(self, column_name):\n",
    "        self.column_name = column_name\n",
    "\n",
    "    def transform(self, df):\n",
    "        # select the relevant column and return it as a numpy array\n",
    "        # set the array type to be string\n",
    "        return np.asarray(df[self.column_name]).astype(str)\n",
    "        \n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define X, y, and X_test\n",
    "\n",
    "X = train[['query', 'Jaccard']]\n",
    "y = train['median_relevance']\n",
    "X_test = test[['query', 'Jaccard']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('query_extractor', TextExtractor('query')), # extract names from df\n",
    "    ('vect', vect),  # extract ngrams from query\n",
    "    ('clf' , clf),   # feed the output through a classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.634811023622\n"
     ]
    }
   ],
   "source": [
    "run_experiment(X, y, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Apply(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Applies a function f element-wise to the numpy array\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fn):\n",
    "        self.fn = np.vectorize(fn)\n",
    "        \n",
    "    def transform(self, data):\n",
    "        # note: reshaping is necessary because otherwise sklearn\n",
    "        # interprets 1-d array as a single sample\n",
    "        return self.fn(data.reshape(data.size, 1))\n",
    "\n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we already imported FeatureUnion earlier, so here goes\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('query_extractor', TextExtractor('query')), # extract names from df\n",
    "    ('text_features', FeatureUnion([\n",
    "        ('vect', vect),  # extract ngrams from query\n",
    "        ('num_words', Apply(lambda s: len(s.split()))), # length of string\n",
    "    ])),\n",
    "    ('clf' , clf),   # feed the output through a classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.635492125984\n"
     ]
    }
   ],
   "source": [
    "run_experiment(X, y, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('query_extractor', TextExtractor(column_name='query')), ('text_features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=T...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 3, ..., 1, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"id\": test[\"id\"], \"prediction\": y_pred})\n",
    "submission.to_csv(\"pipeline_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
